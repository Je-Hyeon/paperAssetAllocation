{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4853d6fa",
   "metadata": {},
   "source": [
    "기존에 만들어둔 predicted corr matrix 기반으로 Fixed K 구현해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c68b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from mvgarch.ugarch import UGARCH\n",
    "from mvgarch.mgarch import DCCGARCH\n",
    "\n",
    "from tools.portfolio import black_litterman, vectorize_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0daad4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0c126f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/asset_cc2.pkl\")\n",
    "\n",
    "window_size = 60\n",
    "rtn = np.log(df).diff().dropna() * 100\n",
    "holding_rtn = (np.log(df) - np.log(df).shift(20)).shift(-20).dropna()[\"1997-05\":] * 100\n",
    "holding_cov = rtn.rolling(window=window_size).cov().shift(-120).dropna()\n",
    "rolling_corr_matrix = rtn.rolling(window=window_size).corr().dropna()[\"1997-05\":]\n",
    "rolling_cov_matrix = rtn.rolling(window=window_size).cov().dropna()[\"1997-05\":]\n",
    "\n",
    "days_lst = rtn.loc[\"2007-01-03\":\"2025-04-16\"].index[40:]\n",
    "range_n_clusters = list(range(2, 10))\n",
    "\n",
    "rtn = rtn[\"1997-05\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87eb7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir(\"results/res2\")\n",
    "predicted_corr_lst = []\n",
    "for file in listdir:\n",
    "    if \"predicted_corr_matrix\" in file:\n",
    "        with open(f\"results/res2/{file}\", 'r', encoding='utf-8') as f:\n",
    "            predicted_corr_lst.append(json.load(f))\n",
    "            \n",
    "predicted_corr_dict = {pd.to_datetime(k): v for d in predicted_corr_lst for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5989d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_vector_dict = {\n",
    "    d: vectorize_corr(rolling_corr_matrix.loc[d].values)\n",
    "    for d in rtn.index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6678cd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 923/4528 [00:33<01:50, 32.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2010-10-29 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1012/4528 [00:36<02:05, 28.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2011-03-10 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1203/4528 [00:43<01:46, 31.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2011-12-13 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2751/4528 [02:32<01:26, 20.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2018-03-02 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3063/4528 [03:43<01:18, 18.67it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2019-05-30 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4528/4528 [06:45<00:00, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error in 2025-04-16 00:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_weight_dict = {}\n",
    "estimated_regime_lst = []\n",
    "\n",
    "km = KMeans(n_clusters=k) # Fixed K\n",
    "\n",
    "i=0\n",
    "for today in tqdm(days_lst[:]):\n",
    "    try:\n",
    "        hist = rtn.loc[:today]\n",
    "        rc = rolling_corr_matrix.loc[:today]\n",
    "        stacked = np.vstack(\n",
    "            [\n",
    "                np.vstack([rc_vector_dict[d] for d in hist.index]),\n",
    "                vectorize_corr(np.array(predicted_corr_dict[today]))\n",
    "            ])\n",
    "\n",
    "        # 3) Fixed KMeans\n",
    "        labels = km.fit_predict(stacked)\n",
    "\n",
    "        # 4) Black–Litterman\n",
    "        idxs = hist.index\n",
    "        labels_series = pd.Series(\n",
    "            labels,\n",
    "            index=list(idxs) + [rtn.loc[today:].index[1]]\n",
    "        )\n",
    "        pred_state = labels_series.iloc[-1]\n",
    "        regs = labels_series[labels_series == pred_state].index\n",
    "        mu_bl, w_bl = black_litterman(\n",
    "            sigma=rolling_cov_matrix.loc[today].values,\n",
    "            w_mkt=np.array([0.05,0.05,0.05,0.05,0.6,0.2]),\n",
    "            p=np.eye(6),\n",
    "            q=holding_rtn.loc[regs].mean().values,\n",
    "            omega=holding_cov.loc[regs].groupby(level=1).mean().values,\n",
    "            tau=0.15,\n",
    "        )\n",
    "        w_bl = np.clip(w_bl, 0, None)\n",
    "        w_bl /= w_bl.sum()\n",
    "\n",
    "        # Save\n",
    "        result_weight_dict[today] = w_bl\n",
    "        estimated_regime_lst.append(labels_series)\n",
    "\n",
    "\n",
    "\n",
    "        if i % 1500 == 0:\n",
    "            serializable_result_w  = {str(k): v.tolist() for k, v in result_weight_dict.items()}\n",
    "            serializable_estimated_regime_lst  = [{str(key):value for key, value in inner_dict.items()} for inner_dict in estimated_regime_lst]\n",
    "            with open(f\"results/res(k3)/result_weightsfull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_result_w, f, ensure_ascii=False, indent=4)\n",
    "            with open(f\"results/res(k3)/estimated_regimefull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_estimated_regime_lst, f, ensure_ascii=False, indent=4)\n",
    "    except:\n",
    "        print(f\"error in {today}\")\n",
    "        continue\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593dd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "serializable_result_w  = {str(k): v.tolist() for k, v in result_weight_dict.items()}\n",
    "serializable_estimated_regime_lst  = [{str(key):value for key, value in inner_dict.items()} for inner_dict in estimated_regime_lst]\n",
    "with open(f\"results/res(k3)/result_weightsfull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_result_w, f, ensure_ascii=False, indent=4)\n",
    "with open(f\"results/res(k3)/estimated_regimefull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_estimated_regime_lst, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Statistical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
