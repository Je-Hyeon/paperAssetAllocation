{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from tools.portfolio import black_litterman, vectorize_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/asset_cc2.pkl\")\n",
    "\n",
    "window_size = 60\n",
    "rtn = np.log(df).diff().dropna() * 100\n",
    "holding_rtn = (np.log(df) - np.log(df).shift(20)).shift(-20).dropna()[\"1997-05\":] * 100\n",
    "holding_cov = rtn.rolling(window=window_size).cov().shift(-120).dropna()\n",
    "rolling_corr_matrix = rtn.rolling(window=window_size).corr().dropna()[\"1997-05\":]\n",
    "rolling_cov_matrix = rtn.rolling(window=window_size).cov().dropna()[\"1997-05\":]\n",
    "\n",
    "days_lst = rtn.loc[\"2007-01-03\":\"2025-04-16\"].index[40:]\n",
    "range_n_clusters = list(range(2, 5))\n",
    "\n",
    "rtn = rtn[\"1997-05\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_vector_dict = {\n",
    "    d: vectorize_corr(rolling_corr_matrix.loc[d].values)\n",
    "    for d in rtn.index\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['brent', 'dxy', 'gold', 'silver', 'snp', 't10']\n",
    "w_mkt = np.array([0.05, 0.05, 0.05, 0.05, 0.6, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4528/4528 [1:35:09<00:00,  1.26s/it]  \n"
     ]
    }
   ],
   "source": [
    "# 속도 최적화를 위해 다음과 같이 개선할 수 있습니다.\n",
    "# 1. corr_vector_dict에서 stacked_corr_matrix를 매번 np.vstack으로 만드는 대신, 미리 numpy array로 만들어두고 슬라이싱만 사용\n",
    "# 2. KMeans의 n_init 파라미터를 1로 줄여 반복 횟수 감소 (정확도에 민감하다면 유지)\n",
    "# 3. silhouette_score 계산을 for문 안에서 best_score 갱신과 함께 처리\n",
    "# 4. holding_rtn, holding_cov, rolling_cov_matrix 등에서 loc 슬라이싱 대신 numpy array로 미리 변환해두고 인덱스 매핑\n",
    "# 5. 불필요한 리스트 변환, dict 변환 최소화\n",
    "# 6. tqdm의 disable 파라미터로 불필요한 출력 방지(필요시)\n",
    "# 7. 예외처리 except Exception as e로 구체화\n",
    "\n",
    "# 1. corr_vector_dict를 numpy array로 변환\n",
    "corr_dates = list(rtn.index)\n",
    "corr_matrix_np = np.stack([corr_vector_dict[d] for d in corr_dates])\n",
    "\n",
    "# 2. 날짜 인덱스 매핑\n",
    "date_to_idx = {d: i for i, d in enumerate(corr_dates)}\n",
    "\n",
    "result_weight_dict = {}\n",
    "estimated_regime_lst = []\n",
    "best_k_dict = {}\n",
    "\n",
    "i = 0\n",
    "for today in tqdm(days_lst[:]):\n",
    "    try:\n",
    "        # hist 인덱스 슬라이싱\n",
    "        hist_idx = date_to_idx[today]\n",
    "        hist_dates = corr_dates[:hist_idx + 1]\n",
    "        stacked_corr_matrix = corr_matrix_np[:hist_idx + 1]\n",
    "\n",
    "        # KMeans Clustering\n",
    "        best_score = -1\n",
    "        best_k = None\n",
    "        best_labels = None\n",
    "        best_model = None\n",
    "\n",
    "        for n_clusters in range_n_clusters:\n",
    "            kmeans = KMeans(n_clusters=n_clusters)\n",
    "            labels = kmeans.fit_predict(stacked_corr_matrix)\n",
    "\n",
    "            # 2. 해당 레이블로 실루엣 스코어 계산\n",
    "            score = silhouette_score(stacked_corr_matrix, labels)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_k = n_clusters\n",
    "                best_labels = labels\n",
    "                best_model = kmeans\n",
    "\n",
    "        best_k_dict[today] = best_k\n",
    "        labels_series = pd.Series(best_labels, index=hist_dates)\n",
    "        estimated_regime_lst.append(labels_series.to_dict())\n",
    "        current_state = labels_series.iloc[-1]\n",
    "        same_regime_date_lst = labels_series[labels_series == current_state].index\n",
    "\n",
    "        # Black-Litterman\n",
    "        # holding_rtn, holding_cov, rolling_cov_matrix는 DataFrame이므로 loc 사용\n",
    "        past_holding_rtn_vector = holding_rtn.loc[same_regime_date_lst].mean().values\n",
    "        past_holding_cov_matrix = holding_cov.loc[same_regime_date_lst].groupby(level=1).mean().values\n",
    "\n",
    "        mu_bl, w_bl = black_litterman(\n",
    "            sigma=rolling_cov_matrix.loc[today].values,\n",
    "            w_mkt=w_mkt,\n",
    "            p=np.identity(len(w_mkt)),\n",
    "            q=past_holding_rtn_vector,\n",
    "            omega=past_holding_cov_matrix,\n",
    "            tau=0.15,\n",
    "        )\n",
    "        w_bl = np.where(w_bl >= 0, w_bl, 0)\n",
    "        w_bl /= np.sum(w_bl)\n",
    "        result_weight_dict[today] = w_bl\n",
    "\n",
    "        # Save\n",
    "        if i % 1000 == 0:\n",
    "            serializable_result_w = {str(k): v.tolist() for k, v in result_weight_dict.items()}\n",
    "            serializable_estimated_regime_lst = [{str(key): value for key, value in inner_dict.items()} \n",
    "                                                 for inner_dict in estimated_regime_lst]\n",
    "            serializable_best_k_dict = {str(k): v for k, v in best_k_dict.items()}\n",
    "\n",
    "            with open(f\"results/withoutPrediction/result_weightsfull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_result_w, f, ensure_ascii=False, indent=4)\n",
    "            with open(f\"results/withoutPrediction/estimated_regimefull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_estimated_regime_lst, f, ensure_ascii=False, indent=4)\n",
    "            with open(f\"results/withoutPrediction/best_k_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(serializable_best_k_dict, f, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"error in {today}: {e}\")\n",
    "        continue\n",
    "    i+=1\n",
    "0\n",
    "# Final Save\n",
    "serializable_result_w = {str(k): v.tolist() for k, v in result_weight_dict.items()}\n",
    "serializable_estimated_regime_lst = [{str(key): value for key, value in inner_dict.items()} \n",
    "                                     for inner_dict in estimated_regime_lst]\n",
    "serializable_best_k_dict = {str(k): v for k, v in best_k_dict.items()}\n",
    "\n",
    "with open(f\"results/withoutPrediction/result_weightsfull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_result_w, f, ensure_ascii=False, indent=4)\n",
    "with open(f\"results/withoutPrediction/estimated_regimefull.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_estimated_regime_lst, f, ensure_ascii=False, indent=4)\n",
    "with open(f\"results/withoutPrediction/best_k_dict.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(serializable_best_k_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
